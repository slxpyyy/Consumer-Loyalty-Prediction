{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f590691-47d0-46e8-aa52-ec4905f73b2c",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e59d069-f5c4-45ac-8b76-ae8c5d0b2569",
   "metadata": {},
   "source": [
    "&emsp;&emsp; Create general combination features and business statistical features; and after the features are created, filter the features based on the Filter method of the Pearson correlation coefficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96e70af-0c85-43fa-b35c-5554e44d516f",
   "metadata": {},
   "source": [
    "### 1. Demo for explanation : Generic composite feature creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a502390b-75fc-40b0-bf8f-1e49f1941db2",
   "metadata": {},
   "source": [
    "&emsp;&emsp;Features created by counting the sum of different discrete features at different value levels and different continuous feature values, and grouping and summing according to card_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6a2353-67a4-4581-b780-e062fdc8b39d",
   "metadata": {},
   "source": [
    "<center><img src=\"https://i.loli.net/2021/10/23/KUTtb32o9eS1MJW.png\" alt=\"image-20211023153800138\" style=\"zoom:67%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d287b57-bdea-41e9-a52b-504eb90af9c7",
   "metadata": {},
   "source": [
    "The data set created by this method can not only represent the consumption of each card_id from as many dimensions as possible, but also can be successfully spliced with the training set/test set, so as to be brought into the model for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e38803d7-b3da-42df-b959-50f05575cfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ecfaff14-0f9d-4d57-ae93-ed4251335393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   card_id  A  B  C  D\n",
       "0        1  1  2  4  7\n",
       "1        2  2  1  5  5\n",
       "2        1  1  2  1  4\n",
       "3        3  2  2  5  8"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame using a dictionary\n",
    "d1 = {'card_id':[1, 2, 1, 3], \n",
    "      'A':[1, 2, 1, 2], \n",
    "      'B':[2, 1, 2, 2], \n",
    "      'C':[4, 5, 1, 5], \n",
    "      'D':[7, 5, 4, 8],}\n",
    "\n",
    "t1 = pd.DataFrame(t1)\n",
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c004b7d-c49c-4f27-9288-211689c6604a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Feature Class\n",
    "numeric_cols = ['C', 'D']\n",
    "category_cols = ['A', 'B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71d979f4-439d-4415-a8db-7c45bad3d9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with id as key and empty dictionary as value\n",
    "features = {}\n",
    "card_all = t1['card_id'].values.tolist()\n",
    "for card in card_all:\n",
    "    features[card] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10b27f8a-ef64-4181-af4e-4de4ef827720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {}, 2: {}, 3: {}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93c5c967-2963-4a7d-85df-56e657cb2da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['card_id', 'A', 'B', 'C', 'D']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of all field names\n",
    "columns = t1.columns.tolist()\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "615b0aa0-1440-4da4-993b-374603f8757a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the index value of card_id in the list\n",
    "idx = columns.index('card_id')\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ce8c08ef-37bf-4ab7-bb67-96f9dbcb03e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index value of discrete field\n",
    "category_cols_index = [columns.index(col) for col in category_cols]\n",
    "category_cols_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "503e10ea-c5d2-46ab-aef7-5605ea206d0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index value of continuous field\n",
    "numeric_cols_index = [columns.index(col) for col in numeric_cols]\n",
    "numeric_cols_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ace64c60-bbfb-49cf-9e14-4db87a777f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining different values of discrete fields and continuous fields in pairs\n",
    "# Simultaneously complete group summation\n",
    "for i in range(t1.shape[0]):\n",
    "    va = t1.loc[i].values\n",
    "    card = va[idx]\n",
    "    for cate_ind in category_cols_index:\n",
    "        for num_ind in numeric_cols_index:\n",
    "            col_name = '&'.join([columns[cate_ind], str(va[cate_ind]), columns[num_ind]])\n",
    "            features[card][col_name] = features[card].get(col_name, 0) + va[num_ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bd7761-411c-4c99-b92b-006df7c684bb",
   "metadata": {},
   "source": [
    "&emsp;&emsp;Then view the final result of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6565ca79-ebf9-420c-85dc-67639835fe92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'A&1&C': 5, 'A&1&D': 11, 'B&2&C': 5, 'B&2&D': 11},\n",
       " 2: {'A&2&C': 5, 'A&2&D': 5, 'B&1&C': 5, 'B&1&D': 5},\n",
       " 3: {'A&2&C': 5, 'A&2&D': 8, 'B&2&C': 5, 'B&2&D': 8}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1024ae8c-58f1-45ab-8e57-5d29f812fcd1",
   "metadata": {},
   "source": [
    "At this time, features is a group summation result under different card_ids after combining different values of discrete variables and continuous variables into new features. Next we convert it to a DataFrame："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f13830a6-2232-41f0-9d0a-f65b05142a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>A&amp;1&amp;C</th>\n",
       "      <th>A&amp;1&amp;D</th>\n",
       "      <th>B&amp;2&amp;C</th>\n",
       "      <th>B&amp;2&amp;D</th>\n",
       "      <th>A&amp;2&amp;C</th>\n",
       "      <th>A&amp;2&amp;D</th>\n",
       "      <th>B&amp;1&amp;C</th>\n",
       "      <th>B&amp;1&amp;D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   card_id  A&1&C  A&1&D  B&2&C  B&2&D  A&2&C  A&2&D  B&1&C  B&1&D\n",
       "0        1    5.0   11.0    5.0   11.0    NaN    NaN    NaN    NaN\n",
       "1        2    NaN    NaN    NaN    NaN    5.0    5.0    5.0    5.0\n",
       "2        3    NaN    NaN    5.0    8.0    5.0    8.0    NaN    NaN"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to df\n",
    "df = pd.DataFrame(features).T.reset_index()\n",
    "\n",
    "# Label all columns\n",
    "cols = df.columns.tolist()\n",
    "\n",
    "# Modify the feature name of df\n",
    "df.columns = ['card_id'] + cols[1:]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939dba78-131d-4573-89db-fe217b8a8102",
   "metadata": {},
   "source": [
    "&emsp;&emsp;This method of feature creation can very efficiently represent the hidden information in more data sets, but this method is prone to produce more null values, and the problem caused by the sparseness of the feature matrix needs to be considered in the subsequent modeling process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb01194c-3b1e-441d-b8f4-24587a27b608",
   "metadata": {},
   "source": [
    "#### 1.2 Create general composite features based on transaction datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4f8ca8-20e9-4f28-8eb3-3cbf8cd214fe",
   "metadata": {},
   "source": [
    "&emsp;&emsp;The transaction read here is the previously created transaction_d_pre.csv dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d60f5a08-27f2-46b2-8f24-2e81a0cbea0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('preprocess/train_pre.csv')\n",
    "test =  pd.read_csv('preprocess/test_pre.csv')\n",
    "transaction = pd.read_csv('preprocess/transaction_d_pre.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4759ce-ca98-42f7-8f29-392b96717b91",
   "metadata": {},
   "source": [
    "- Field type annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "548fd17c-fb67-4d50-a1b6-54042bd0539d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label discrete or continuous fields\n",
    "numeric_cols = ['purchase_amount', 'installments']\n",
    "\n",
    "category_cols = ['authorized_flag', 'city_id', 'category_1',\n",
    "       'category_3', 'merchant_category_id','month_lag','most_recent_sales_range',\n",
    "                 'most_recent_purchases_range', 'category_4',\n",
    "                 'purchase_month', 'purchase_hour_section', 'purchase_day']\n",
    "\n",
    "id_cols = ['card_id', 'merchant_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf92a02-804c-4f51-9a1f-a5b60616e5cd",
   "metadata": {},
   "source": [
    "- feature creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3080b314-5ab5-422e-86cf-dad5e6d4a4ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142.746732711792 s\n",
      "241.50783610343933 s\n",
      "338.9149408340454 s\n",
      "436.4667372703552 s\n",
      "533.113107919693 s\n",
      "629.66761469841 s\n",
      "727.1969571113586 s\n",
      "824.3946213722229 s\n",
      "921.0717754364014 s\n",
      "1017.7034878730774 s\n",
      "1114.4361855983734 s\n",
      "1211.2046930789948 s\n",
      "1308.0264575481415 s\n",
      "1404.8067374229431 s\n",
      "1501.533932209015 s\n",
      "1598.396145105362 s\n",
      "1695.2529389858246 s\n",
      "1792.5994687080383 s\n",
      "1889.7299542427063 s\n",
      "1987.0093190670013 s\n",
      "2084.849946975708 s\n",
      "2183.5546836853027 s\n",
      "2281.704159259796 s\n",
      "2379.819750070572 s\n",
      "2478.2387039661407 s\n",
      "2576.8626248836517 s\n",
      "2676.383053302765 s\n",
      "2777.3995122909546 s\n",
      "2879.5466351509094 s\n",
      "2981.8099772930145 s\n",
      "3085.8226635456085 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dictionary for storing data\n",
    "features = {}\n",
    "card_all = train['card_id'].append(test['card_id']).values.tolist()\n",
    "for card in card_all:\n",
    "    features[card] = {}\n",
    "     \n",
    "# Indexes that mark fields of different types\n",
    "columns = transaction.columns.tolist()\n",
    "idx = columns.index('card_id')\n",
    "category_cols_index = [columns.index(col) for col in category_cols]\n",
    "numeric_cols_index = [columns.index(col) for col in numeric_cols]\n",
    "\n",
    "# record running time\n",
    "s = time.time()\n",
    "num = 0\n",
    "\n",
    "# Execute the loop, and record the time during the process\n",
    "for i in range(transaction.shape[0]):\n",
    "    va = transaction.loc[i].values\n",
    "    card = va[idx]\n",
    "    for cate_ind in category_cols_index:\n",
    "        for num_ind in numeric_cols_index:\n",
    "            col_name = '&'.join([columns[cate_ind], va[cate_ind], columns[num_ind]])\n",
    "            features[card][col_name] = features[card].get(col_name, 0) + va[num_ind]\n",
    "    num += 1\n",
    "    if num%1000000==0:\n",
    "        print(time.time()-s, \"s\")\n",
    "del transaction\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e720c14b-f469-4b52-bb07-62a3a143ed50",
   "metadata": {},
   "source": [
    "&emsp;&emsp;After extracting the features, the next step is to merge the transaction data features into the training set and test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f35fcb9-756d-43ff-9233-d05398c53f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to dataframe\n",
    "df = pd.DataFrame(features).T.reset_index()\n",
    "del features\n",
    "cols = df.columns.tolist()\n",
    "df.columns = ['card_id'] + cols[1:]\n",
    "\n",
    "# Generate training and test sets\n",
    "train = pd.merge(train, df, how='left', on='card_id')\n",
    "test =  pd.merge(test, df, how='left', on='card_id')\n",
    "del df\n",
    "train.to_csv(\"preprocess/train_dict.csv\", index=False)\n",
    "test.to_csv(\"preprocess/test_dict.csv\", index=False)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443daeeb-cc57-4118-9e6d-6765124b6841",
   "metadata": {},
   "source": [
    "&emsp;&emsp;Simply view the basic situation of the data set:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9915a415-4602-4fca-a67e-e50a699d9b2a",
   "metadata": {},
   "source": [
    "<center><img src=\"https://i.loli.net/2021/10/23/ZY75eSk3pAayoJn.png\" alt=\"image-20211023161451438\" style=\"zoom:67%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f6a231-9449-407f-81ee-5b04d2fac602",
   "metadata": {},
   "source": [
    "### 2.Create business statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea680b36-7cd2-4830-94c4-e6fe8e92f263",
   "metadata": {},
   "source": [
    "&emsp;&emsp;Another method, First group according to card_id, then count different fields and related statistics in each group, and then use them as features and bring them into modeling. Its basic structural features are as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0c3e22-7aa0-4b0f-b46d-35199b970cdf",
   "metadata": {},
   "source": [
    "<center><img src=\"https://i.loli.net/2021/10/23/NupDc9JnBbHRPgU.png\" alt=\"image-20211023162730619\" style=\"zoom:80%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859f4af6-3da4-40fb-b818-e58ce2192fe6",
   "metadata": {},
   "source": [
    "The features constructed by this method will not have a large number of missing values, and there will be relatively few new columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a353954d-c4ba-4136-bfa7-f12186e76769",
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction = pd.read_csv('preprocess/transaction_g_pre.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d04bd2b-726c-446a-8e56-6afc4980cb56",
   "metadata": {},
   "source": [
    "- Field type annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ef47e7ce-beaa-4598-9a0c-e258c4097e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label discrete or continuous fields\n",
    "numeric_cols = ['authorized_flag',  'category_1', 'installments',\n",
    "       'category_3',  'month_lag','purchase_month','purchase_day','purchase_day_diff', 'purchase_month_diff',\n",
    "       'purchase_amount', 'category_2', \n",
    "       'purchase_month', 'purchase_hour_section', 'purchase_day',\n",
    "       'most_recent_sales_range', 'most_recent_purchases_range', 'category_4']\n",
    "categorical_cols = ['city_id', 'merchant_category_id', 'merchant_id', 'state_id', 'subsector_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cca76d-ad08-4668-bbc5-f9be3b560a9a",
   "metadata": {},
   "source": [
    "- feature extraction process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ace5ff6b-ab39-4447-9e70-bcadda5f9857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty dictionary\n",
    "aggs = {}\n",
    "\n",
    "# Continuous/discrete field statistics extraction range\n",
    "for col in numeric_cols:\n",
    "    aggs[col] = ['nunique', 'mean', 'min', 'max','var','skew', 'sum']\n",
    "for col in categorical_cols:\n",
    "    aggs[col] = ['nunique']    \n",
    "aggs['card_id'] = ['size', 'count']\n",
    "cols = ['card_id']\n",
    "\n",
    "# Statistical calculation with groupby\n",
    "for key in aggs.keys():\n",
    "    cols.extend([key+'_'+stat for stat in aggs[key]])\n",
    "\n",
    "df = transaction[transaction['month_lag']<0].groupby('card_id').agg(aggs).reset_index()\n",
    "df.columns = cols[:1] + [co+'_hist' for co in cols[1:]]\n",
    "\n",
    "df2 = transaction[transaction['month_lag']>=0].groupby('card_id').agg(aggs).reset_index()\n",
    "df2.columns = cols[:1] + [co+'_new' for co in cols[1:]]\n",
    "df = pd.merge(df, df2, how='left',on='card_id')\n",
    "\n",
    "df2 = transaction.groupby('card_id').agg(aggs).reset_index()\n",
    "df2.columns = cols\n",
    "df = pd.merge(df, df2, how='left',on='card_id')\n",
    "del transaction\n",
    "gc.collect()\n",
    "\n",
    "# 生成训练集与测试集\n",
    "train = pd.merge(train, df, how='left', on='card_id')\n",
    "test =  pd.merge(test, df, how='left', on='card_id')\n",
    "del df\n",
    "train.to_csv(\"preprocess/train_groupby.csv\", index=False)\n",
    "test.to_csv(\"preprocess/test_groupby.csv\", index=False)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da996a7d-73aa-4a90-891a-c3321ae11897",
   "metadata": {},
   "source": [
    "View the basic situation of the data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf5d09c-55a7-4be7-9928-334b0d1c0630",
   "metadata": {},
   "source": [
    "<center><img src=\"https://i.loli.net/2021/10/23/HpI1QuM6ZvtkS7f.png\" alt=\"image-20211023162707542\" style=\"zoom:67%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed493b4c-5817-4c0e-9ba9-eeb5158f412d",
   "metadata": {},
   "source": [
    "### 3.data merge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb72f2ab-bc5e-4112-8fb2-c81d5aa215ef",
   "metadata": {},
   "source": [
    "Only by merging it can it be further brought in for modeling. The merging process is relatively simple. You only need to splice the train_dict(test_dict) and train_group(test_group) horizontally according to the card_id, and then remove the duplicate columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c4e7219-4175-49b5-9068-af17e59a786c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = pd.read_csv(\"preprocess/train_dict.csv\")\n",
    "test_dict = pd.read_csv(\"preprocess/test_dict.csv\")\n",
    "train_groupby = pd.read_csv(\"preprocess/train_groupby.csv\")\n",
    "test_groupby = pd.read_csv(\"preprocess/test_groupby.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdb5384-0a0e-4898-8cec-f3fb907d1422",
   "metadata": {},
   "source": [
    "- remove duplicate columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32862990-9fb9-4d9f-8b8c-472966eacfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for co in train_dict.columns:\n",
    "    if co in train_groupby.columns and co!='card_id':\n",
    "        del train_groupby[co]\n",
    "for co in test_dict.columns:\n",
    "    if co in test_groupby.columns and co!='card_id':\n",
    "        del test_groupby[co]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d044090-71ba-4d5a-8416-031df430a6f0",
   "metadata": {},
   "source": [
    "- Splicing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cd4ac85-4c6c-47e6-9050-3bc43f3f067a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge(train_dict, train_groupby, how='left', on='card_id').fillna(0)\n",
    "test = pd.merge(test_dict, test_groupby, how='left', on='card_id').fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480bf3c8-fd9a-4b8c-90cd-db0276cf4fec",
   "metadata": {},
   "source": [
    ">  the above operation fills the missing value with 0. The missing value here is not a real missing value. The missing value is just a value that has no statistical result during the feature creation process. Logically speaking, these values are actually 0. Therefore, the filling of missing values here is equivalent to data completion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa427b96-7d6f-41f4-92fe-c9980212d141",
   "metadata": {},
   "source": [
    "- Data storage and memory management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b4c7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"preprocess/train.csv\", index=False)\n",
    "test.to_csv(\"preprocess/test.csv\", index=False)\n",
    "\n",
    "del train_dict, test_dict, train_groupby, test_groupby\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
